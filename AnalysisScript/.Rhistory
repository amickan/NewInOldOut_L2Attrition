num <- which(master$English == pretest$English[i])
if (length(num)!= 0){
pretest$Dutch[i] <- as.character(master$Dutch[num])
}
}
View(pretest)
write.table(pretest, "FullPretest.txt", sep = "\t", quote = F, row.names = F, col.names = T)
### Honours project data analysis ###
require(reshape)
require(data.table)
require(here)
A = c(601:603, 608, 610:620, 622, 623, 625:631)
post <- read.table(here("CompleteDataset_Honours.txt"), header = T)
post<-post[!(post$Subject_nr == 604 | post$Subject_nr == 624),]
post <- droplevels(post)
# setting variables
post$Subject_nr <- as.factor(post$Subject_nr)
post$Condition <- as.factor(post$Condition)
post$Errorfact <- as.factor(post$Error)
# new corrected for reaction time
post$RTdiff <- post$RT_pre - post$RT_new
post$Prelog <- log(post$RT_pre)
post$RTdifflog <- post$Prelog - post$RT_new_log
# log-transform RTs
post$RT_new_log <- log(post$RT_new)
# new corrected for reaction time
post$RTdiff <- post$RT_pre - post$RT_new
post$Prelog <- log(post$RT_pre)
post$RTdifflog <- post$Prelog - post$RT_new_log
# exclude trials in which articles were used from RT analysis
for (i in 1:nrow(post)){
if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0){
} else if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0) {
} else if (is.na(post$ArticlesPost[i]) == 0 | is.na(post$ArticlesPre[i]) == 0){
post$RT_new[i] <- NA
post$RT_pre[i] <- NA
post$Prelog[i] <- NA
post$RT_new_log[i] <- NA
post$RTdiff[i] <- NA
post$RTdifflog[i] <- NA
}
}
# check how many trials per person we have left
table(post[is.na(post$RTdiff)==0,]$Subject_nr)
table(post[is.na(post$RTdiff)==0,]$Subject_nr, post[is.na(post$RTdiff)==0,]$Condition) # per condition
# percentage of article traisl per person per condition
article <- post[(is.na(post$ArticlesPre)==0 | is.na(post$ArticlesPost)==0),]
article1 <- (table(article$Subject_nr, article$Condition)/23)*100
article2 <- (table(article$Subject_nr)/46)*100
### deleting trials of words that were already known in Spanish before the learning phaser
known <- read.delim("KnownWords.txt")
for (i in 1:nrow(known)){
pNumber <- known$PP[i]
num <- which(tolower(post[post$Subject_nr == pNumber,]$Spanish_Label) == tolower(known$Word[i]))
if (length(num)!= 0 ){
post[post$Subject_nr == pNumber,]$RT_new[num] <- NA
post[post$Subject_nr == pNumber,]$RT_pre[num] <- NA
post[post$Subject_nr == pNumber,]$Prelog[num] <- NA
post[post$Subject_nr == pNumber,]$RT_new_log[num] <- NA
post[post$Subject_nr == pNumber,]$RTdiff[num] <- NA
post[post$Subject_nr == pNumber,]$RTdifflog[num] <- NA
post[post$Subject_nr == pNumber,]$Error[num] <- NA
}
}
########## Plots with GGplot ###########
require(plyr)
require(ggplot2)
require(lme4)
require(lmerTest)
require(lmtest)
# setting contrasts to the mean of each condition
contrasts(post$Condition) <- c(-0.5,0.5)
# turning my factors into numerical factors reflecting a dummy coding
post$ConditionN <- (-(as.numeric(post$Condition)-2))-0.5
## Full model with maximal random effects structure
modelfull <- glmer(Error ~ ConditionN + (1|Item) + (1+ConditionN|Subject_nr), family = "binomial", control=glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)), data = post)
summary(modelfull)
fit <- glmer(Error ~ ConditionN + (1|Item) + (1+ConditionN|Subject_nr), family = "binomial", control=glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)), data = post)
r2.corr.mer <- function(m) {
lmfit <-  lm(model.response(model.frame(m)) ~ fitted(m))
summary(lmfit)$r.squared
}
r2.corr.mer(fit)
fixef(fit)["ConditionN"] <- -0.15
library(simr)
fixef(fit)["ConditionN"] <- -0.15
power <- powerSim(fit, nsim = 200, test = fcompare(Rtdifflog~ 1))
power
power <- powerSim(fit, nsim = 200, test = fcompare(Error~ 1))
summary(fit)
power <- powerSim(fit, nsim = 200)
power
fitrt <- lmer(RTdifflog ~ ConditionN + (1|Item) + (1+ConditionN|Subject_nr), control=lmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)),data = post)
r2.corr.mer(fitrt)
summary(fitrt)
fixef(fitrt)["ConditionN"] <- -0.25
power <- powerSim(fitrt, nsim = 200, test = fcompare(RTdifflog~ 1))
power
fixef(fitrt)["
fixef(fitrt)
summary(fit)
summary(fitrt)
### Honours project data analysis ###
require(reshape)
require(data.table)
require(here)
A = c(601:603, 608, 610:620, 622, 623, 625:631)
post <- read.table(here("CompleteDataset_Honours.txt"), header = T)
post<-post[!(post$Subject_nr == 604 | post$Subject_nr == 624),]
post <- droplevels(post)
A = c(601:603, 608, 610:620, 622, 623, 625:631)
post <- read.table(here("CompleteDataset_Honours.txt"), header = T)
# setting variables
post$Subject_nr <- as.factor(post$Subject_nr)
post$Condition <- as.factor(post$Condition)
post$Errorfact <- as.factor(post$Error)
# checking RTs
min(post$RT_new, na.rm=T)
hist(post$RT_new)
shapiro.test(post$RT_new) ## data are not normal
# log-transform RTs
post$RT_new_log <- log(post$RT_new)
# checking coding instances with error code "6"
subset <- post[is.na(post$ErrorDetail)==0 && post$ErrorDetail == 6,] # only one case
# new corrected for reaction time
post$RTdiff <- post$RT_pre - post$RT_new
post$Prelog <- log(post$RT_pre)
post$RTdifflog <- post$Prelog - post$RT_new_log
###### How many people used articles on each test #####
table(post$Subject_nr, post$ArticlesPre) # Pps 604, 618, 624 and 630 used a lot of articles, let's try to exclude them and see what happens to the effect
# exclude trials in which articles were used from RT analysis
for (i in 1:nrow(post)){
if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0){
} else if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0) {
} else if (is.na(post$ArticlesPost[i]) == 0 | is.na(post$ArticlesPre[i]) == 0){
post$RT_new[i] <- NA
post$RT_pre[i] <- NA
post$Prelog[i] <- NA
post$RT_new_log[i] <- NA
post$RTdiff[i] <- NA
post$RTdifflog[i] <- NA
}
}
# check how many trials per person we have left
table(post[is.na(post$RTdiff)==0,]$Subject_nr)
table(post[is.na(post$RTdiff)==0,]$Subject_nr, post[is.na(post$RTdiff)==0,]$Condition) # per condition
### Honours project data analysis ###
require(reshape)
require(data.table)
require(here)
A = c(601:603, 608, 610:620, 622, 623, 625:631)
post <- read.table(here("CompleteDataset_Honours.txt"), header = T)
post<-post[!(post$Subject_nr == 604 | post$Subject_nr == 624),]
post <- droplevels(post)
# setting variables
post$Subject_nr <- as.factor(post$Subject_nr)
post$Condition <- as.factor(post$Condition)
post$Errorfact <- as.factor(post$Error)
# checking RTs
min(post$RT_new, na.rm=T)
hist(post$RT_new)
shapiro.test(post$RT_new) ## data are not normal
# log-transform RTs
post$RT_new_log <- log(post$RT_new)
# checking coding instances with error code "6"
subset <- post[is.na(post$ErrorDetail)==0 && post$ErrorDetail == 6,] # only one case
# new corrected for reaction time
post$RTdiff <- post$RT_pre - post$RT_new
post$Prelog <- log(post$RT_pre)
post$RTdifflog <- post$Prelog - post$RT_new_log
###### How many people used articles on each test #####
table(post$Subject_nr, post$ArticlesPre) # Pps 604, 618, 624 and 630 used a lot of articles, let's try to exclude them and see what happens to the effect
# exclude trials in which articles were used from RT analysis
for (i in 1:nrow(post)){
if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0){
} else if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0) {
} else if (is.na(post$ArticlesPost[i]) == 0 | is.na(post$ArticlesPre[i]) == 0){
post$RT_new[i] <- NA
post$RT_pre[i] <- NA
post$Prelog[i] <- NA
post$RT_new_log[i] <- NA
post$RTdiff[i] <- NA
post$RTdifflog[i] <- NA
}
}
# check how many trials per person we have left
table(post[is.na(post$RTdiff)==0,]$Subject_nr)
table(post[is.na(post$RTdiff)==0,]$Subject_nr, post[is.na(post$RTdiff)==0,]$Condition) # per condition
### deleting trials of words that were already known in Spanish before the learning phaser
known <- read.delim("KnownWords.txt")
for (i in 1:nrow(known)){
pNumber <- known$PP[i]
num <- which(tolower(post[post$Subject_nr == pNumber,]$Spanish_Label) == tolower(known$Word[i]))
if (length(num)!= 0 ){
post[post$Subject_nr == pNumber,]$RT_new[num] <- NA
post[post$Subject_nr == pNumber,]$RT_pre[num] <- NA
post[post$Subject_nr == pNumber,]$Prelog[num] <- NA
post[post$Subject_nr == pNumber,]$RT_new_log[num] <- NA
post[post$Subject_nr == pNumber,]$RTdiff[num] <- NA
post[post$Subject_nr == pNumber,]$RTdifflog[num] <- NA
post[post$Subject_nr == pNumber,]$Error[num] <- NA
}
}
post[post$ErrorDetail == 6,] ->error
View(error)
View(post)
View(error)
### Honours project data analysis ###
require(reshape)
require(data.table)
require(here)
A = c(601:603, 608, 610:620, 622, 623, 625:631)
post <- read.table(here("CompleteDataset_Honours.txt"), header = T)
postrt<-post[!(post$Subject_nr == 604 | post$Subject_nr == 624),]
postrt <- droplevels(postrt)
str(post)
str(postrt)
# setting variables
post$Subject_nr <- as.factor(post$Subject_nr)
post$Condition <- as.factor(post$Condition)
post$Errorfact <- as.factor(post$Error)
postrt$Subject_nr <- as.factor(postrt$Subject_nr)
postrt$Condition <- as.factor(postrt$Condition)
postrt$Errorfact <- as.factor(postrt$Error)
# setting variables
post$Subject_nr <- as.factor(post$Subject_nr)
post$Condition <- as.factor(post$Condition)
post$Errorfact <- as.factor(post$Error)
# checking RTs
min(post$RT_new, na.rm=T)
hist(post$RT_new)
shapiro.test(post$RT_new) ## data are not normal
# log-transform RTs
post$RT_new_log <- log(post$RT_new)
# checking coding instances with error code "6"
subset <- post[is.na(post$ErrorDetail)==0 && post$ErrorDetail == 6,] # only one case
# new corrected for reaction time
post$RTdiff <- post$RT_pre - post$RT_new
post$Prelog <- log(post$RT_pre)
post$RTdifflog <- post$Prelog - post$RT_new_log
###### How many people used articles on each test #####
table(post$Subject_nr, post$ArticlesPre) # Pps 604, 618, 624 and 630 used a lot of articles, let's try to exclude them and see what happens to the effect
# exclude trials in which articles were used from RT analysis
for (i in 1:nrow(post)){
if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0){
} else if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0) {
} else if (is.na(post$ArticlesPost[i]) == 0 | is.na(post$ArticlesPre[i]) == 0){
post$RT_new[i] <- NA
post$RT_pre[i] <- NA
post$Prelog[i] <- NA
post$RT_new_log[i] <- NA
post$RTdiff[i] <- NA
post$RTdifflog[i] <- NA
}
}
table(post[is.na(post$RTdiff)==0,]$Subject_nr, post[is.na(post$RTdiff)==0,]$Condition) # per condition
table(post[is.na(post$Error)==0,]$Subject_nr, post[is.na(post$Error)==0,]$Condition) # per condition
afterexcl <- table(post[is.na(post$RTdiff)==0,]$Subject_nr, post[is.na(post$RTdiff)==0,]$Condition) # per condition
beforeexcl <- table(post[is.na(post$Error)==0,]$Subject_nr, post[is.na(post$Error)==0,]$Condition) # per condition
rtexcl <- beforeexcl-afterexcl
perc <- (rtexcl/23)*100
avepercexcl <- (perc[,1]+perc[,2])/2
avepercexcl
perc
A = c(601:603, 608, 610:620, 622, 623, 625:631)
post <- read.table(here("CompleteDataset_Honours.txt"), header = T)
# setting variables
post$Subject_nr <- as.factor(post$Subject_nr)
post$Condition <- as.factor(post$Condition)
post$Errorfact <- as.factor(post$Error)
# checking RTs
min(post$RT_new, na.rm=T)
hist(post$RT_new)
shapiro.test(post$RT_new) ## data are not normal
# log-transform RTs
post$RT_new_log <- log(post$RT_new)
# checking coding instances with error code "6"
subset <- post[is.na(post$ErrorDetail)==0 && post$ErrorDetail == 6,] # only one case
# new corrected for reaction time
post$RTdiff <- post$RT_pre - post$RT_new
post$Prelog <- log(post$RT_pre)
post$RTdifflog <- post$Prelog - post$RT_new_log
###### How many people used articles on each test #####
table(post$Subject_nr, post$ArticlesPre) # Pps 604, 618, 624 and 630 used a lot of articles, let's try to exclude them and see what happens to the effect
beforeexcl <- table(post[is.na(post$RTdiff)==0,]$Subject_nr, post[is.na(post$RTdiff)==0,]$Condition) # per condition
# exclude trials in which articles were used from RT analysis
for (i in 1:nrow(post)){
if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0){
} else if (is.na(post$ArticlesPost[i]) == 0 && is.na(post$ArticlesPre[i]) == 0) {
} else if (is.na(post$ArticlesPost[i]) == 0 | is.na(post$ArticlesPre[i]) == 0){
post$RT_new[i] <- NA
post$RT_pre[i] <- NA
post$Prelog[i] <- NA
post$RT_new_log[i] <- NA
post$RTdiff[i] <- NA
post$RTdifflog[i] <- NA
}
}
# check how many trials per person we have left
table(post[is.na(post$RTdiff)==0,]$Subject_nr)
afterexcl <- table(post[is.na(post$RTdiff)==0,]$Subject_nr, post[is.na(post$RTdiff)==0,]$Condition) # per condition
rtexcl <- beforeexcl-afterexcl
perc <- (rtexcl/23)*100
avepercexcl <- (perc[,1]+perc[,2])/2
perc
avepercexcl
postrt<-post[!(post$Subject_nr == 604 | post$Subject_nr == 624 | post$Subject_nr == 630),]
postrt <- droplevels(postrt)
ddply(post, .(Condition, Subject_nr),
summarise, N=length(Error),
mean   = mean(Error, na.rm = TRUE),
sem = sd(Error, na.rm = TRUE)/sqrt(N)) -> aggregatedError
aggregated_means_error <- ddply(post, .(Condition),
summarise,
condition_mean = mean(Error,na.rm = T),
condition_sem = sd(Error,na.rm = T)/sqrt(length(Error[!is.na(Error)])))
aggregatedError <- merge(aggregatedError, aggregated_means_error, by = c("Condition"))
aggregated_means_error$condition_mean <- aggregated_means_error$condition_mean*100
aggregated_means_error$condition_sem <- aggregated_means_error$condition_sem*100
aggregatedError$mean <- aggregatedError$mean*100
aggregatedError$sem <- aggregatedError$sem*100
aggregatedError$condition_sem <- aggregatedError$condition_sem*100
aggregatedError$condition_mean <- aggregatedError$condition_mean*100
lineplot <- ggplot(aggregatedError, aes(y = mean, x = Condition, group = Subject_nr))
lineplot + geom_point(color="darkgrey") +
geom_line(color="darkgrey") +
geom_point(aes(y = condition_mean,
color = Condition), color="black") +
geom_text(aes(label=Subject_nr)) +
geom_line(aes(y = condition_mean,color="red")) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem,
color = "red",
na.rm = T),
width = 0.5) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
scale_x_discrete(labels=c("Interference", "No interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Percentage correctly recalled words in Spanish") +
# scale_color_manual(guide=F, "Frequency Condition", values=c("dodgerblue4","firebrick"),labels=c("High","Low")) +
theme_bw()
barplot <- ggplot(aggregated_means_error, aes(y = condition_mean, x = Condition, fill = Condition))
barplot + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem),
width = 0.5, position=position_dodge(0.9)) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
coord_cartesian(ylim=c(0,5)) +
scale_x_discrete(labels=c("Interference", "No Interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Percentage incorrectly recalled words in English") +
scale_fill_grey(labels=c("Interference","No Interference")) +
theme_bw()
########## Plots with GGplot ###########
require(plyr)
require(ggplot2)
ddply(post, .(Condition, Subject_nr),
summarise, N=length(Error),
mean   = mean(Error, na.rm = TRUE),
sem = sd(Error, na.rm = TRUE)/sqrt(N)) -> aggregatedError
aggregated_means_error <- ddply(post, .(Condition),
summarise,
condition_mean = mean(Error,na.rm = T),
condition_sem = sd(Error,na.rm = T)/sqrt(length(Error[!is.na(Error)])))
aggregatedError <- merge(aggregatedError, aggregated_means_error, by = c("Condition"))
aggregated_means_error$condition_mean <- aggregated_means_error$condition_mean*100
aggregated_means_error$condition_sem <- aggregated_means_error$condition_sem*100
aggregatedError$mean <- aggregatedError$mean*100
aggregatedError$sem <- aggregatedError$sem*100
aggregatedError$condition_mean <- aggregatedError$condition_mean*100
aggregatedError$condition_sem <- aggregatedError$condition_sem*100
lineplot <- ggplot(aggregatedError, aes(y = mean, x = Condition, group = Subject_nr))
lineplot + geom_point(color="darkgrey") +
geom_line(color="darkgrey") +
geom_point(aes(y = condition_mean,
color = Condition), color="black") +
geom_text(aes(label=Subject_nr)) +
geom_line(aes(y = condition_mean,color="red")) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem,
color = "red",
na.rm = T),
width = 0.5) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
scale_x_discrete(labels=c("Interference", "No interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Percentage correctly recalled words in Spanish") +
# scale_color_manual(guide=F, "Frequency Condition", values=c("dodgerblue4","firebrick"),labels=c("High","Low")) +
theme_bw()
barplot <- ggplot(aggregated_means_error, aes(y = condition_mean, x = Condition, fill = Condition))
barplot + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem),
width = 0.5, position=position_dodge(0.9)) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
coord_cartesian(ylim=c(0,5)) +
scale_x_discrete(labels=c("Interference", "No Interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Percentage incorrectly recalled words in English") +
scale_fill_grey(labels=c("Interference","No Interference")) +
theme_bw()
#### Plot for RTs ###
ddply(post, .(Condition, Subject_nr),
summarise, N=length(RT_new),
mean   = mean(RT_new, na.rm = TRUE),
sem = sd(RT_new, na.rm = TRUE)/sqrt(N)) -> aggregatedrt
#### Plot for RTs ###
ddply(postrt, .(Condition, Subject_nr),
summarise, N=length(RT_new),
mean   = mean(RT_new, na.rm = TRUE),
sem = sd(RT_new, na.rm = TRUE)/sqrt(N)) -> aggregatedrt
aggregated_means_rt<- ddply(postrt, .(Condition),
summarise,
condition_mean = mean(RT_new,na.rm = T),
condition_sem = sd(RT_new,na.rm = T)/sqrt(length(RT_new[!is.na(RT_new)])))
aggregatedrt <- merge(aggregatedrt, aggregated_means_rt, by = c("Condition"))
barplot <- ggplot(aggregated_means_rt, aes(y = condition_mean, x = Condition, fill = Condition))
barplot + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem),
width = 0.5, position=position_dodge(0.9)) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
scale_x_discrete(labels=c("Interference", "No Interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Naming latencies in ms") +
scale_fill_grey(labels=c("Interference","No Interference")) +
theme_bw()
aggregated_means_rt
#### Plot for RTs difference ###
ddply(postrt, .(Condition, Subject_nr),
summarise, N=length(RTdiff),
mean   = mean(RTdiff, na.rm = TRUE),
sem = sd(RTdiff, na.rm = TRUE)/sqrt(N)) -> aggregatedrtdiff
aggregated_means_rtdiff<- ddply(postrt, .(Condition),
summarise,
condition_mean = mean(RTdiff,na.rm = T),
condition_sem = sd(RTdiff,na.rm = T)/sqrt(length(RTdiff[!is.na(RTdiff)])))
aggregatedrtdiff <- merge(aggregatedrtdiff, aggregated_means_rtdiff, by = c("Condition"))
barplot <- ggplot(aggregated_means_rtdiff, aes(y = condition_mean, x = Condition, fill = Condition))
barplot + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem),
width = 0.5, position=position_dodge(0.9)) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
scale_x_discrete(labels=c("Interference", "No Interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Speed up in naming latencies from English pre- to posttest (in ms)") +
scale_fill_grey(labels=c("Interference","No Interference")) +
theme_bw()
levels(postrt$Subject_nr)
post$Accuracy <- 1-post$Error
ddply(post, .(Condition, Subject_nr),
summarise, N=length(Accuracy),
mean   = mean(Accuracy, na.rm = TRUE),
sem = sd(Accuracy, na.rm = TRUE)/sqrt(N)) -> aggregatedAcc
aggregated_means_acc <- ddply(post, .(Condition),
summarise,
condition_mean = mean(Accuracy,na.rm = T),
condition_sem = sd(Accuracy,na.rm = T)/sqrt(length(Accuracy[!is.na(Accuracy)])))
aggregatedAcc <- merge(aggregatedAcc, aggregated_means_acc, by = c("Condition"))
aggregated_means_acc$condition_mean <- aggregated_means_acc$condition_mean*100
aggregated_means_acc$condition_sem <- aggregated_means_acc$condition_sem*100
aggregatedAcc$mean <- aggregatedAcc$mean*100
aggregatedAcc$sem <- aggregatedAcc$sem*100
aggregatedAcc$condition_mean <- aggregatedAcc$condition_mean*100
aggregatedAcc$condition_sem <- aggregatedAcc$condition_sem*100
barplot <- ggplot(aggregated_means_acc, aes(y = condition_mean, x = Condition, fill = Condition))
barplot + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem),
width = 0.5, position=position_dodge(0.9)) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
coord_cartesian(ylim=c(90,100)) +
scale_x_discrete(labels=c("Interference", "No Interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Percentage correctly recalled words in English") +
scale_fill_grey(labels=c("Interference","No Interference")) +
theme_bw()
barplot <- ggplot(aggregated_means_acc, aes(y = condition_mean, x = Condition, fill = Condition))
barplot + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem),
width = 0.5, position=position_dodge(0.9)) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
coord_cartesian(ylim=c(93,100)) +
scale_x_discrete(labels=c("Interference", "No Interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Percentage correctly recalled words in English") +
scale_fill_grey(labels=c("Interference","No Interference")) +
theme_bw()
## Simple Anova for accuracy
## Arcsine transformed data Anova
anova <- aov(Error ~ Condition, data = post)
summary(anova)
###### Modelling for RTs #####
# simple Anova for RTs (log-transformed)
anova_rt <- aov(RT_new_log ~ Condition, data = post)
summary(anova_rt)
barplot <- ggplot(aggregated_means_rtdiff, aes(y = condition_mean, x = Condition, fill = Condition))
barplot + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem),
width = 0.5, position=position_dodge(0.9)) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
coord_cartesian(ylim=c(0,600)) +
scale_x_discrete(labels=c("Interference", "No Interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Speed up in naming latencies from English pre- to posttest (in ms)") +
scale_fill_grey(labels=c("Interference","No Interference")) +
theme_bw()
barplot <- ggplot(aggregated_means_rtdiff, aes(y = condition_mean, x = Condition, fill = Condition))
barplot + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=condition_mean-condition_sem,
ymax=condition_mean+condition_sem),
width = 0.5, position=position_dodge(0.9)) +
theme(axis.text = element_text(size = 20), axis.title = element_text(size = 20)) +
coord_cartesian(ylim=c(0,800)) +
scale_x_discrete(labels=c("Interference", "No Interference"), breaks = 1:2, expand = c(0.1,0.1)) +
ylab("Speed up in naming latencies from English pre- to posttest (in ms)") +
scale_fill_grey(labels=c("Interference","No Interference")) +
theme_bw()
